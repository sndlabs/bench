# Benchmark Report

**Run ID**: lm-eval_20250729_103822
**Timestamp**: Tue Jul 29 10:40:00 KST 2025
**Model**: gpt2
**Tasks**: arc_easy
**Framework**: lm-eval
**Hardware Profile**: apple-m4-max

## Results Summary

See data.json for detailed results.

## Logs

- Benchmark log: /Users/victor/GitHub/snd-bench/logs/lm-eval_20250729_103822.log
- W&B data: /Users/victor/GitHub/snd-bench/runs/lm-eval_20250729_103822/wandb_data.json
- AI summary: /Users/victor/GitHub/snd-bench/runs/lm-eval_20250729_103822/summary.md

## Static Site

Results are available on the dashboard at index.html

